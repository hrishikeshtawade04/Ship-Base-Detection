{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Flatten, Dense, Lambda, Convolution2D, Cropping2D, Dropout, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from keras import backend as K\n",
    "import glob\n",
    "import sklearn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_train_test_data(test_size=0.2):\n",
    "    coast = glob.glob(\"MASATI-v1\\coast\\*\")\n",
    "    land = glob.glob(\"MASATI-v1\\land\\*\")\n",
    "    sea = glob.glob(\"MASATI-v1\\sea\\*\")\n",
    "    multi = glob.glob(\"MASATI-v1\\multi\\*\")\n",
    "    detail = glob.glob(\"MASATI-v1\\detail\\*\")\n",
    "    ship = glob.glob(\"MASATI-v1\\ship\\*\")\n",
    "    coast_ship = glob.glob(\"MASATI-v1\\coast_ship\\*\")\n",
    "\n",
    "    y_coast = np.zeros(len(coast))\n",
    "    y_land = np.zeros(len(land))\n",
    "    y_sea = np.zeros(len(sea))\n",
    "    y_multi = np.ones(len(multi))\n",
    "    y_ship = np.ones(len(ship))\n",
    "    y_detail = np.ones(len(detail))\n",
    "    y_coast_ship = np.ones(len(coast_ship))\n",
    "\n",
    "    X = np.concatenate([coast,land,sea,multi,ship,detail,coast_ship])\n",
    "\n",
    "    print(\"Total Dataset = \", X.shape)\n",
    "    y = np.concatenate([y_coast,y_land,y_sea,y_multi,y_ship,y_detail,y_coast_ship])\n",
    "    print(\"Total Labels = \", len(y))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)                                                \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Dataset =  (5202,)\n",
      "Total Labels =  5202\n",
      "(4161,)\n",
      "(4161,)\n",
      "(1041,)\n",
      "(1041,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = create_train_test_data()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f5bbf42470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hist = np.histogram(y_train, bins=2,range = (0,1))\n",
    "plt.hist(y_train, bins='auto')\n",
    "plt.hist(y_test, bins='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a generator\n",
    "def generator(X,y, batch_size=32):\n",
    "    num_samples = len(X)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        combined = list(zip(X,y))\n",
    "        sklearn.utils.shuffle(combined) # shuffle data\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = combined[offset:offset+batch_size] # batch of 32 feeded in the batch samples\n",
    "            #batch_Y = Y[offset:offset+batch_size]\n",
    "            images = [] # empty arrays for processing\n",
    "            labels = []\n",
    "            for batch_sample in batch_samples:\n",
    "                #print( batch_sample[0].split('/')[-1])\n",
    "                #name = '../data/IMG/'+batch_sample[0].split('\\\\')[-1] #batch_sample[0].split('/')[-1] # <--- should be used if code running on windows instead of EC2\n",
    "                center_image = cv2.imread(batch_sample[0])\n",
    "                center_image = cv2.cvtColor(center_image, cv2.COLOR_BGR2RGB) # takes care of the BGR to RGB conversion. since finally the simulator outputs RGB\n",
    "                #center_angle = float(batch_sample[1])\n",
    "                images.append(center_image)\n",
    "                labels.append(batch_sample[1])\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(labels)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train) # shuffle data again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile and train the model using the generator function\n",
    "train_generator = generator(X_train, y_train, batch_size=32)\n",
    "#validation_generator = generator(validation_samples, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kapil\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), strides=(2, 2), activation=\"relu\")`\n",
      "  import sys\n",
      "C:\\Users\\kapil\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 5), strides=(2, 2), activation=\"relu\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\kapil\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), strides=(2, 2), activation=\"relu\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\kapil\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  del sys.path[0]\n",
      "C:\\Users\\kapil\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\kapil\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Preprocess incoming data, centered around zero with small standard deviation \n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(256,256,3)))\n",
    "# Cropping to focus only on road\n",
    "#model.add(Cropping2D(cropping=((50,20), (0,0))))\n",
    "#Covolution Layer 1 \n",
    "model.add(Convolution2D(24, 5, 5, activation='relu', subsample=(2, 2)))\n",
    "#Covolution Layer 2\n",
    "model.add(Convolution2D(36, 5, 5, activation='relu', subsample=(2, 2)))\n",
    "#Covolution Layer 3\n",
    "model.add(Convolution2D(48, 5, 5, activation='relu', subsample=(2, 2)))\n",
    "#Covolution Layer 4\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "#Covolution Layer 5\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "#Dropout Layer \n",
    "model.add(Dropout(p = 0.5)) # can be tuned\n",
    "# Flatten for passing to Fully Connected layers\n",
    "model.add(Flatten())\n",
    "# FC 1\n",
    "model.add(Dense(100))#, activation='elu')) <--- Can add relu here too. But I thought it wasn't necessary later on.\n",
    "# FC 2\n",
    "model.add(Dense(50))#, activation='elu'))\n",
    "# FC 3\n",
    "model.add(Dense(10))#, activation='elu'))\n",
    "# FC 4\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kapil\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \n",
      "C:\\Users\\kapil\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., epochs=3, steps_per_epoch=4161)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4161/4161 [==============================] - 265s 64ms/step - loss: 0.0373 - acc: 0.9654\n",
      "Epoch 2/3\n",
      "4161/4161 [==============================] - 261s 63ms/step - loss: 0.0091 - acc: 0.9977\n",
      "Epoch 3/3\n",
      "4161/4161 [==============================] - 261s 63ms/step - loss: 0.0064 - acc: 0.9989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17f649a0d30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy']) # Using default learning rate and MSE as loss function\n",
    "model.fit_generator(train_generator, samples_per_epoch= len(X_train), nb_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = load_model('model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a generator\n",
    "def testCreator(X):\n",
    "    images = []\n",
    "    num_samples = len(X)\n",
    "    for path in X:\n",
    "        #print( batch_sample[0].split('/')[-1])\n",
    "        #name = '../data/IMG/'+batch_sample[0].split('\\\\')[-1] #batch_sample[0].split('/')[-1] # <--- should be used if code running on windows instead of EC2\n",
    "        center_image = cv2.imread(path)\n",
    "        center_image = cv2.cvtColor(center_image, cv2.COLOR_BGR2RGB) # takes care of the BGR to RGB conversion. since finally the simulator outputs RGB\n",
    "        #center_angle = float(batch_sample[1])\n",
    "        images.append(center_image)\n",
    "        # trim image to only see section with road\n",
    "    X_test = np.array(images)\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_frames_to_video():\n",
    "    output = glob.glob(\"output\\*\")\n",
    "    frame_array = []\n",
    "    #print(frame_array[0])\n",
    "    \n",
    "    #out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, (600,600))\n",
    "    for i in output:\n",
    "        # writing to a image array\n",
    "        img = cv2.imread(i)\n",
    "        frame_array.append(img)\n",
    "        #cv2.resizeWindow('image', 1000,1000)\n",
    "        #cv2.imshow('image',frame_array[i])    \n",
    "        #cv2.waitKey(500)\n",
    "        #cv2.destroyAllWindows()\n",
    "    out = cv2.VideoWriter('D:\\output.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (600,600))\n",
    "    for i in range(len(frame_array)):\n",
    "        out.write(frame_array[i])\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1041/1041 [==============================] - 4s 3ms/step\n",
      "(1041, 1)\n",
      "[0.96926033]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b21f108c97e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresizeWindow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PREDICTED_CLASSES = model1.predict_classes(testCreator(X_test), batch_size=1041, verbose=1)\n",
    "#print(type(PREDICTED_CLASSES))\n",
    "#PREDICTED_CLASSES = (PREDICTED_CLASSES>=0.5)\n",
    "y_test = y_test.reshape(1041,1)\n",
    "temp = sum(y_test == PREDICTED_CLASSES)/len(y_test)\n",
    "print(y_test.shape)\n",
    "print(temp)\n",
    "\n",
    "\n",
    "\n",
    "images = testCreator(X_test)\n",
    "\n",
    "font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "bottomLeftCornerOfText = (10,150)\n",
    "fontScale              = 1\n",
    "fontColor              = (255,255,255)\n",
    "lineType               = 2\n",
    "\n",
    "combined = zip(images,PREDICTED_CLASSES)\n",
    "frame_array = []\n",
    "it = 0\n",
    "for i in combined:\n",
    "    \n",
    "    cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "    img = cv2.cvtColor(i[0], cv2.COLOR_BGR2RGB)\n",
    "    if(i[1] == 1):\n",
    "                    cv2.putText(img,'Ships', \n",
    "                    bottomLeftCornerOfText, \n",
    "                    font, \n",
    "                    fontScale,\n",
    "                    fontColor,\n",
    "                    lineType)\n",
    "    else:\n",
    "                  cv2.putText(img,'Not a Ship', \n",
    "                    bottomLeftCornerOfText, \n",
    "                    font, \n",
    "                    fontScale,\n",
    "                    fontColor,\n",
    "                    lineType)\n",
    "    cv2.imwrite(\"output/\" + str(it)+\".png\",img)\n",
    "    it = it+1\n",
    "    frame_array.append(img)\n",
    "    cv2.resizeWindow('image', 1000,1000)\n",
    "    cv2.imshow('image',img)    \n",
    "    cv2.waitKey(500)\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
